{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your current DB connection is with:  <mysql.connector.connection_cext.CMySQLConnection object at 0x7ff4af2a2390>\n",
      "\n",
      "STARTING EXTRACTION...\n",
      "RUNNING...\n",
      "Data frame loading complete.\n",
      "\n",
      "Iterations performed:  31\n",
      "TOTAL Process time:  191.88926637700933 s\n",
      "Average iteration time:  1.1850192627100642 s\n",
      "Average BASE CPU:  2.8612903225806448\n",
      "Average BASE RAM:  2.8612903225806448\n",
      "Average CPU Performance  5.958064516129033\n",
      "Average RAM Performance  -0.003225806451612949\n",
      "Average CPU utilization:  8.819354838709677\n",
      "Average RAM utilization:  29.70322580645163 \n",
      "\n",
      "\n",
      "STARTING TRANSFORMATION...\n",
      "RUNNING...\n",
      "Pandas transformation metrics captured.\n",
      "\n",
      "Iterations performed:  31\n",
      "TOTAL Process time:  164.5493087950017 s\n",
      "Average iteration time:  0.28146363019280424 s\n",
      "Average BASE CPU:  2.761290322580646\n",
      "Average BASE RAM:  2.761290322580646\n",
      "Average CPU Performance  4.5451612903225795\n",
      "Average RAM Performance  0.003225806451612949\n",
      "Average CPU utilization:  7.306451612903226\n",
      "Average RAM utilization:  29.712903225806468 \n",
      "\n",
      "\n",
      "STARTING cuDF TRANSFORMATION\n",
      "RUNNING...\n",
      "cuDF medium load transformation metrics captured.\n",
      "cuDF performance metrics captured loading complete.\n",
      "\n",
      "Iterations performed:  31\n",
      "TOTAL Process time:  162.67075234699587 s\n",
      "Average iteration time:  0.2419819372899515 s\n",
      "Average BASE CPU:  1.9806451612903222\n",
      "Average BASE RAM:  1.9806451612903222\n",
      "Average CPU Performance  4.219354838709678\n",
      "Average RAM Performance  0.0\n",
      "Average CPU utilization:  6.199999999999998\n",
      "Average RAM utilization:  29.78387096774192 \n",
      "\n",
      "\n",
      "STARTING LOAD...\n",
      "Load database connection is:  Engine(mysql+mysqlconnector://root:***@127.0.0.1/datalake)\n",
      "RUNNING...\n",
      "Loading metrics captured loading complete.\n",
      "\n",
      "Iterations performed:  31\n",
      "TOTAL Process time:  373.7537386030017 s\n",
      "Average iteration time:  7.050934084354066 s\n",
      "Average BASE CPU:  2.680645161290323\n",
      "Average BASE RAM:  2.680645161290323\n",
      "Average CPU Performance  4.25483870967742\n",
      "Average RAM Performance  0.8225806451612905\n",
      "Average CPU utilization:  6.935483870967741\n",
      "Average RAM utilization:  43.26129032258064 \n",
      "\n",
      "\n",
      "ETL is complete\n",
      "Elapsed ETL time is:  14.88287683919989  minutes\n"
     ]
    }
   ],
   "source": [
    "# Import packages for use\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "import psutil\n",
    "import cudf\n",
    "from extract_load_functions import extraction, loading, performance\n",
    "\n",
    "#set export location\n",
    "exportLocation = r'/home/jeff/'\n",
    "\n",
    "#set number of test runs to prefrom\n",
    "iterations = 31\n",
    "\n",
    "# Connect to MySQL database\n",
    "mydb = mysql.connector.connect(host=\"127.0.0.1\",\n",
    "                               user=\"root\",\n",
    "                               passwd=\"********\",\n",
    "                               database=\"project1\")\n",
    "\n",
    "print(\"Your current DB connection is with: \",mydb)\n",
    "\n",
    "\n",
    "etlTimerStart = time.perf_counter() \n",
    "### HEAVY EXTRACTION ###\n",
    "##################################################################################################################\n",
    "# Join the order_line and item tables and capture CPU, RAM and elapsed time to perform operations\n",
    "# Pull the item table from MySQL\n",
    "\n",
    "sql = \"select * from order_header inner join order_line on order_header.ponum = order_line.ponum inner join item on order_line.orderedItem = item.orderedItem;\"\n",
    "heavyExtraction  = extraction(mydb,sql,iterations,exportLocation,\"heavyExtractionPrfm.csv\")\n",
    "\n",
    "\n",
    "### HEAVY TRANSFORMATION ###\n",
    "##################################################################################################################\n",
    "# Preform heavy transformation workload.  Item, order_line, and orderHeader will be joined.  All item descriptions \n",
    "# with \"Blue\" in them are changed to \"Navy.\"  Any clothing items with \"Tee\" will be modified to \"CottonTee\"\n",
    "# Additionallay a computer column called extedned_price will be created by multiplying eaches and item_price.\n",
    "\n",
    "column_names = [\"base_CPU\",\"base_RAM\",\"CPU_utilization\", \"RAM_utilization\", \"CPU_d\",\"RAM_d\",\"elapsed_time\"]\n",
    "heavyPrfm = pd.DataFrame(columns = column_names)\n",
    "\n",
    "print(\"STARTING TRANSFORMATION...\")\n",
    "print(\"RUNNING...\")\n",
    "\n",
    "#Run n iterations to collect transformation df of performance metrics\n",
    "transTimerStart= time.perf_counter() \n",
    "for sampleNoTransform in range(iterations):\n",
    "    heavyTrans = heavyExtraction\n",
    "    \n",
    "    time.sleep(5)\n",
    "    #collect base settings\n",
    "    baseCPU = psutil.cpu_percent()\n",
    "    baseRAM = psutil.virtual_memory().percent\n",
    "    \n",
    "    # Start Timer and progress tracker\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    \n",
    "    #Working Code\n",
    "    heavyTrans.item_desc = heavyTrans.item_desc.str.replace('Blue', 'Navy', regex=True)\n",
    "    heavyTrans.item_desc = heavyTrans.item_desc.str.replace('Tee', 'CottonTee', regex=True)\n",
    "    heavyTrans['extended_price'] = heavyTrans.eaches_qty * heavyTrans.selling_price\n",
    "    sampleCPU = psutil.cpu_percent()\n",
    "    sampleRAM = psutil.virtual_memory().percent\n",
    "    \n",
    "    #Stop timer  \n",
    "    stop = time.perf_counter()\n",
    "    \n",
    "    \n",
    "    heavyPrfm = heavyPrfm.append(pd.DataFrame({'base_CPU': baseCPU,\n",
    "                                               'base_RAM': baseRAM,\n",
    "                                               'CPU_utilization': sampleCPU,\n",
    "                                               'RAM_utilization':  sampleRAM,\n",
    "                                               'CPU_d': sampleCPU-baseCPU,\n",
    "                                               'RAM_d': sampleRAM - baseRAM,\n",
    "                                               'elapsed_time':stop - start},\n",
    "                                              index=[1]), ignore_index=True)\n",
    "    \n",
    "    # Remove duplicate columns\n",
    "    heavyTrans = heavyTrans.loc[:,~heavyTrans.columns.duplicated()]\n",
    "transTimerEnd= time.perf_counter() \n",
    "\n",
    "#Export pandas performance to csv\n",
    "heavyPrfm.to_csv (r'/home/jeff/heavyPrfm.csv', index = False, header=True)\n",
    "\n",
    "print(\"Pandas transformation metrics captured.\\n\")\n",
    "performance(heavyPrfm,iterations,transTimerStart,transTimerEnd)\n",
    "\n",
    "### HEAVY cuDF TRANSFORMATION ###\n",
    "##################################################################################################################\n",
    "# Preform heavy transformation workload.  Item, order_line, and orderHeader will be joined.  All item descriptions \n",
    "# with \"Blue\" in them are changed to \"Navy.\"  Any clothing items with \"Tee\" will be modified to \"CottonTee\"\n",
    "# Additionallay a computer column called extedned_price will be created by multiplying eaches and item_price.\n",
    "\n",
    "heavyTrans = heavyExtraction\n",
    "column_names = [\"base_CPU\",\"base_RAM\",\"CPU_utilization\", \"RAM_utilization\", \"CPU_d\",\"RAM_d\",\"elapsed_time\"]\n",
    "heavyPrfmCU = pd.DataFrame(columns = column_names)\n",
    "heavyTrans['request_date'].astype('datetime64')\n",
    "\n",
    "    \n",
    "print(\"STARTING cuDF TRANSFORMATION\")\n",
    "print(\"RUNNING...\")\n",
    "\n",
    "#Run 30 iterations to collect transformation df of performance metrics\n",
    "transCuTimerStart = time.perf_counter() \n",
    "for sampleNoTransform in range(iterations):\n",
    "    \n",
    "    time.sleep(5)\n",
    "    #collect base settings\n",
    "    baseCPU = psutil.cpu_percent()\n",
    "    baseRAM = psutil.virtual_memory().percent\n",
    "    \n",
    "    # Start Timer and progress tracker\n",
    "    start = time.perf_counter()\n",
    "    ## Transform pandas df to cuDF\n",
    "    heavyTransCU = cudf.DataFrame.from_pandas(heavyTrans)\n",
    "    \n",
    "    #Working Code\n",
    "    heavyTransCU.item_desc = heavyTransCU.item_desc.str.replace('Blue', 'Navy', regex=True)\n",
    "    heavyTransCU.item_desc = heavyTransCU.item_desc.str.replace('Tee', 'CottonTee', regex=True)\n",
    "    heavyTransCU['extended_price'] = heavyTransCU.eaches_qty * heavyTransCU.selling_price\n",
    "    sampleCPU = psutil.cpu_percent()\n",
    "    sampleRAM = psutil.virtual_memory().percent\n",
    "    \n",
    "    #Stop timer  \n",
    "    stop = time.perf_counter()\n",
    "    \n",
    "    \n",
    "    heavyPrfmCU = heavyPrfmCU.append(pd.DataFrame({'base_CPU': baseCPU,\n",
    "                                               'base_RAM': baseRAM,\n",
    "                                               'CPU_utilization': sampleCPU,\n",
    "                                               'RAM_utilization':  sampleRAM,\n",
    "                                               'CPU_d': sampleCPU-baseCPU,\n",
    "                                               'RAM_d': sampleRAM - baseRAM,\n",
    "                                               'elapsed_time':stop - start},\n",
    "                                              index=[1]), ignore_index=True)\n",
    "transCuTimerEnd= time.perf_counter() \n",
    "\n",
    "print(\"cuDF medium load transformation metrics captured.\")\n",
    "\n",
    "#Export cuDF performance to csv\n",
    "heavyPrfmCU.to_csv (r'/home/jeff/heavyPrfmCU.csv', index = False, header=True)\n",
    "\n",
    "print(\"cuDF performance metrics captured loading complete.\\n\")\n",
    "performance(heavyPrfmCU,iterations,transCuTimerStart,transCuTimerEnd)\n",
    "\n",
    "### HEAVY LOADING ###\n",
    "##################################################################################################################\n",
    "loading(heavyTrans,'heavyTransformation',iterations, exportLocation, \"heavyLoadPrfm.csv\")\n",
    "\n",
    "etlTimerEnd = time.perf_counter() \n",
    "print('ETL is complete')\n",
    "print('Elapsed ETL time is: ', (etlTimerEnd-etlTimerStart)/60, ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
