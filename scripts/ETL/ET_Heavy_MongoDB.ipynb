{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING EXTRACTION...\n",
      "RUNNING...\n",
      "Data frame loading complete.\n",
      "\n",
      "Iterations performed:  31\n",
      "TOTAL Process time:  202.79465493099997 s\n",
      "Average iteration time:  1.5359190660974784 s\n",
      "Average BASE CPU:  1.5806451612903225\n",
      "Average BASE RAM:  29.34193548387095\n",
      "Average CPU Performance  4.1580645161290315\n",
      "Average RAM Performance  0.03225806451612915\n",
      "Average CPU utilization:  5.738709677419354\n",
      "Average RAM utilization:  29.37419354838708 \n",
      "\n",
      "\n",
      "STARTING TRANSFORMATION...\n",
      "RUNNING...\n",
      "Pandas transformation metrics captured.\n",
      "\n",
      "Iterations performed:  31\n",
      "TOTAL Process time:  170.94979942499776 s\n",
      "Average iteration time:  0.5089123751616083 s\n",
      "Average BASE CPU:  1.6741935483870967\n",
      "Average BASE RAM:  29.777419354838692\n",
      "Average CPU Performance  4.199999999999999\n",
      "Average RAM Performance  0.01935483870967735\n",
      "Average CPU utilization:  5.874193548387098\n",
      "Average RAM utilization:  29.796774193548373 \n",
      "\n",
      "\n",
      "Starting cuDF TRANSFORMATION...\n",
      "RUNNING...\n",
      "cuDF performance metrics captured loading complete.\n",
      "\n",
      "Iterations performed:  31\n",
      "TOTAL Process time:  160.11486847500782 s\n",
      "Average iteration time:  0.05837973383735986 s\n",
      "Average BASE CPU:  1.5870967741935482\n",
      "Average BASE RAM:  30.867741935483874\n",
      "Average CPU Performance  4.138709677419355\n",
      "Average RAM Performance  0.04516129032258071\n",
      "Average CPU utilization:  5.725806451612904\n",
      "Average RAM utilization:  30.912903225806453 \n",
      "\n",
      "\n",
      "STARTING LOAD...\n",
      "RUNNING...\n",
      "Loading metrics captured loading complete.\n",
      "\n",
      "Iterations performed:  31\n",
      "TOTAL Process time:  231.64879897699575 s\n",
      "Average iteration time:  2.410980503225038 s\n",
      "Average BASE CPU:  1.8000000000000003\n",
      "Average BASE RAM:  31.767741935483865\n",
      "Average CPU Performance  4.270967741935484\n",
      "Average RAM Performance  0.009677419354838733\n",
      "Average CPU utilization:  6.070967741935484\n",
      "Average RAM utilization:  31.777419354838703 \n",
      "\n",
      "\n",
      "ETL is complete\n",
      "Elapsed ETL time is:  12.810706803533442  minutes\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "import psutil\n",
    "import cudf\n",
    "from extract_load_functions_mongodb import extraction, loading, performance\n",
    "\n",
    "#set export location\n",
    "exportLocation = r'/home/jeff/'\n",
    "\n",
    "#set number of test runs to prefrom\n",
    "iterations = 31\n",
    "\n",
    "# Connect to MongoDb\n",
    "myclient = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = myclient.ds7330 \n",
    "item = db.item\n",
    "order_line = db.order_line\n",
    "orderHeader = db.orderHeader\n",
    "\n",
    "\n",
    "etlTimerStart = time.perf_counter()    \n",
    "# HEAVY EXTRACTION #\n",
    "###################################################################################################################\n",
    "### Pull item table and capture CPU, RAM and elapsed time to perform operations\n",
    "\n",
    "extractionTimerStart = time.perf_counter()\n",
    "### Run 30 iterations to collect a df of performance metrics\n",
    "### light extraction performance metrics\n",
    "column_names = [\"base_CPU\",\"base_RAM\",\"CPU_utilization\", \"RAM_utilization\", \"CPU_d\",\"RAM_d\",\"elapsed_time\"]\n",
    "heavyExtractionPrfm = pd.DataFrame(columns = column_names)\n",
    "\n",
    "### base metrics\n",
    "print(\"STARTING EXTRACTION...\")\n",
    "print(\"RUNNING...\")\n",
    "\n",
    "### Run n iterations to collect a df of performance metrics\n",
    "for sampleNo in range(iterations):\n",
    "    \n",
    "    time.sleep(5)\n",
    "    #collect base settings\n",
    "    baseCPU = psutil.cpu_percent()\n",
    "    baseRAM = psutil.virtual_memory().percent\n",
    "    \n",
    "    #Initiate timer for query\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    #insert data into dataFrame\n",
    "    itemdf = pd.DataFrame(list(item.find()))\n",
    "    order_linedf = pd.DataFrame(list(order_line.find()))\n",
    "    orderHeaderdf = pd.DataFrame(list(orderHeader.find()))\n",
    "    sampleCPU = psutil.cpu_percent()\n",
    "    sampleRAM = psutil.virtual_memory().percent\n",
    "    \n",
    "    #Stop timer  \n",
    "    stop = time.perf_counter()\n",
    "\n",
    "    #load df with performance metrics    \n",
    "    heavyExtractionPrfm = heavyExtractionPrfm.append(pd.DataFrame({'base_CPU': baseCPU,\n",
    "                                                         'base_RAM': baseRAM,\n",
    "                                                         'CPU_utilization': sampleCPU,\n",
    "                                                         'RAM_utilization': sampleRAM,\n",
    "                                                         'CPU_d': sampleCPU-baseCPU,\n",
    "                                                         'RAM_d': sampleRAM - baseRAM,\n",
    "                                                         'elapsed_time':stop - start},\n",
    "                                                          index=[1]), ignore_index=True)\n",
    "extractionTimerEnd= time.perf_counter()   \n",
    "\n",
    "print(\"Data frame loading complete.\\n\")\n",
    "performance(heavyExtractionPrfm, iterations, extractionTimerStart,extractionTimerEnd)\n",
    "\n",
    "#Export DF to csv\n",
    "heavyExtractionPrfm.to_csv (r'/home/jeff/heavyExtractionPrfm_MongoDB.csv', index = False, header=True)\n",
    "\n",
    "#### Heavy TRANSFORMATION ####\n",
    "###################################################################################################################\n",
    "# Preform medium transformation workload.  In this case, join orderline and item tables, identify all item descriptions with \"Blue\" in them \n",
    "# and change them to \"Navy\"\n",
    "\n",
    "#Cast datatypes to objects\n",
    "order_linedf[['Line', 'eaches_qty']] = order_linedf[['Line', 'eaches_qty']].apply(pd.to_numeric) \n",
    "order_linedf[['Order', 'orderedItem','Ponum']] = order_linedf[['Order', 'orderedItem','Ponum']].astype(str) \n",
    "\n",
    "itemdf[['selling_price']] = itemdf[['selling_price']].apply(pd.to_numeric)\n",
    "itemdf[['orderedItem']] = itemdf[['orderedItem']].astype(str)\n",
    "\n",
    "orderHeaderdf[['site_num']] = orderHeaderdf[['site_num']].apply(pd.to_numeric)\n",
    "orderHeaderdf[['Ponum']] = orderHeaderdf[['Ponum']].astype(str)\n",
    "\n",
    "column_names = [\"base_CPU\",\"base_RAM\",\"CPU_utilization\", \"RAM_utilization\", \"CPU_d\",\"RAM_d\",\"elapsed_time\"]\n",
    "heavyTransPrfm = pd.DataFrame(columns = column_names)\n",
    "#lightTrans.item_desc.str.contains(\"^Blue\")\n",
    "\n",
    "print(\"STARTING TRANSFORMATION...\")\n",
    "print(\"RUNNING...\")\n",
    "\n",
    "transTimerStart = time.perf_counter()\n",
    "#Run 30 iterations to collect transformation df of performance metrics\n",
    "\n",
    "for sampleNoTransform in range(iterations):\n",
    "    \n",
    "    time.sleep(5)\n",
    "    #collect base settings\n",
    "    baseCPU = psutil.cpu_percent()\n",
    "    baseRAM = psutil.virtual_memory().percent\n",
    "    \n",
    "    # Start Timer and progress tracker\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    #Working Code\n",
    "    itemtrans = itemdf.drop(index=itemdf.index[[-1]])\n",
    "    order_linetrans = order_linedf.drop(index=order_linedf.index[[-1]])\n",
    "    orderHeadertrans = order_linedf.drop(index=orderHeaderdf.index[[-1]])\n",
    "    \n",
    "    itemtrans =itemdf.drop(itemdf.columns[[0]], axis = 1) \n",
    "    order_linetrans = order_linedf.drop(order_linedf.columns[[0]], axis = 1) \n",
    "    orderHeadertrans = orderHeaderdf.drop(orderHeaderdf.columns[[0]], axis = 1) \n",
    "    \n",
    "    medium = order_linetrans.merge(right=itemtrans, on=\"orderedItem\")\n",
    "    heavy = orderHeadertrans.merge(right=medium, on=\"Ponum\")\n",
    "    \n",
    "    heavy.item_desc = heavy.item_desc.str.replace('Blue', 'Navy', regex=True)\n",
    "    heavy.item_desc = heavy.item_desc.str.replace('Tee', 'CottonTee', regex=True)\n",
    "    heavy['extended_price'] = heavy.selling_price * medium.eaches_qty\n",
    "        \n",
    "    sampleCPU = psutil.cpu_percent()\n",
    "    sampleRAM = psutil.virtual_memory().percent\n",
    "    \n",
    "    #Stop timer  \n",
    "    stop = time.perf_counter()\n",
    "    \n",
    "    \n",
    "    heavyTransPrfm = heavyTransPrfm.append(pd.DataFrame({'base_CPU': baseCPU,\n",
    "                                                         'base_RAM': baseRAM,\n",
    "                                                         'CPU_utilization': sampleCPU,\n",
    "                                                         'RAM_utilization':  sampleRAM,\n",
    "                                                         'CPU_d': sampleCPU-baseCPU,\n",
    "                                                         'RAM_d': sampleRAM - baseRAM,\n",
    "                                                         'elapsed_time':stop - start},\n",
    "                                                          index=[1]), ignore_index=True)\n",
    "transTimerEnd= time.perf_counter() \n",
    "\n",
    "print(\"Pandas transformation metrics captured.\\n\")\n",
    "performance(heavyTransPrfm,iterations,transTimerStart,transTimerEnd)\n",
    "\n",
    "\n",
    "# Export Light Transformation Performance to local\n",
    "heavyTransPrfm.to_csv (r'/home/jeff/heavyTransPrfm_mongoDB.csv', index = False, header=True)\n",
    "\n",
    "\n",
    "#### cuDF TRANSFORMATION ####\n",
    "###################################################################################################################\n",
    "\n",
    "column_names = [\"base_CPU\",\"base_RAM\",\"CPU_utilization\", \"RAM_utilization\", \"CPU_d\",\"RAM_d\",\"elapsed_time\"]\n",
    "heavyTransPrfmCU = pd.DataFrame(columns = column_names)\n",
    "\n",
    "print(\"Starting cuDF TRANSFORMATION...\")\n",
    "print(\"RUNNING...\")\n",
    "\n",
    "#Run 30 iterations to collect transformation df of performance metrics\n",
    "transCuTimerStart = time.perf_counter()\n",
    "for sampleNoTransform in range(iterations):\n",
    "    time.sleep(5)\n",
    "    #collect base settings\n",
    "    baseCPU = psutil.cpu_percent()\n",
    "    baseRAM = psutil.virtual_memory().percent\n",
    "    \n",
    "    ## Transform pandas df to cuDF\n",
    "    itemCU = cudf.DataFrame.from_pandas(itemtrans)\n",
    "    order_lineCU = cudf.DataFrame.from_pandas(order_linetrans)\n",
    "    orderheaderCU = cudf.DataFrame.from_pandas(orderHeadertrans)\n",
    "    \n",
    "    # Start Timer and progress tracker\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    #Working Code\n",
    "    joined_dataCU = order_lineCU.merge(right=itemCU, on=\"orderedItem\")\n",
    "    heavyCU = orderheaderCU.merge(right=joined_dataCU, on=\"Ponum\")\n",
    "    \n",
    "    heavyCU.item_desc = heavyCU.item_desc.str.replace('Blue', 'Navy', regex=True)\n",
    "    heavyCU.item_desc = heavyCU.item_desc.str.replace('Tee', 'CottonTee', regex=True)\n",
    "    heavyCU['extended_price'] = heavyCU.selling_price * heavyCU.eaches_qty\n",
    "    sampleCPU = psutil.cpu_percent()\n",
    "    sampleRAM = psutil.virtual_memory().percent\n",
    "    \n",
    "    #Stop timer  \n",
    "    stop = time.perf_counter()\n",
    "    \n",
    "    heavyTransPrfmCU = heavyTransPrfmCU.append(pd.DataFrame({'base_CPU': baseCPU,\n",
    "                                                         'base_RAM': baseRAM,\n",
    "                                                         'CPU_utilization': sampleCPU,\n",
    "                                                         'RAM_utilization':  sampleRAM,\n",
    "                                                         'CPU_d': sampleCPU-baseCPU,\n",
    "                                                         'RAM_d': sampleRAM - baseRAM,\n",
    "                                                         'elapsed_time':stop - start},\n",
    "                                                          index=[1]), ignore_index=True)\n",
    "transCuTimerEnd = time.perf_counter() \n",
    "\n",
    "print(\"cuDF performance metrics captured loading complete.\\n\")\n",
    "performance(heavyTransPrfmCU,iterations,transCuTimerStart,transCuTimerEnd)\n",
    "\n",
    "# Export medium cuDF Transformation Performance to local\n",
    "heavyTransPrfmCU.to_csv (r'/home/jeff/heavyTransPrfmCU_mongoDB.csv', index = False, header=True)\n",
    "\n",
    "#### Load data ####\n",
    "###################################################################################################################\n",
    "loading(myclient,'heavy', heavy, iterations, exportLocation, \"heavyMongoDBLoad.csv\")\n",
    "\n",
    "etlTimerEnd = time.perf_counter() \n",
    "print('ETL is complete')\n",
    "print('Elapsed ETL time is: ', (etlTimerEnd-etlTimerStart)/60, ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
